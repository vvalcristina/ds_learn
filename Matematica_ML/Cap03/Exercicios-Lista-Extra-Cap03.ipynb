{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Matemática Para Machine Learning</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista Extra de Exercícios  - Capítulo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo desta lista de exercícios é você praticar os principais conceitos estudados neste capítulo, ao mesmo tempo que desenvolve suas habilidades em lógica de programação com a linguagem Python. \n",
    "\n",
    "Caso tenha dúvidas, isso é absolutamente normal e faça um trabalho de pesquisa a fim de relembrar o formato das operações matemáticas.\n",
    "\n",
    "Quando encontrar o formato de uma operação que resolva o exercício proposto, use a linguagem Python para representar esta operação. Em essência, é assim que aplicamos Matemática Para Machine Learning, construindo algoritmos e representando esses algoritmos em linguagem de programação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maioria das pessoas considera a Matemática e a Física, assustadoras bestas das quais é melhor manter a distância. Computadores, no entanto, podem nos ajudar a domar a complexidade e a aritmética tediosa das manipulações associadas a esses assuntos. De fato, Matemática e Física são muito mais acessíveis, uma vez que você tem o poder de computadores do seu lado.\n",
    "\n",
    "Divirta-se!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import *\n",
    "from scipy.linalg import *\n",
    "from matplotlib.pyplot import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considere os vetores v1 e v2 abaixo para resolver os exercícios de 1 a 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vetores\n",
    "v1 = array([1., 2., 3.]) \n",
    "v2 = array([2, 0, 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1 - Multiplique o vetor V1 por 3 e divida o vetor V2 por 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução V1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução V2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2 - Faça uma combinação linear entre eles. Multiplique o vetor 1 por 3 e multiplique o vetor v2 por 5. Então some os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3 - Encontre o produto escalar entre os vetores v1 e v2.\n",
    "\n",
    "Dica: O produto escalar é um único número resultado da multiplicação entre todos os elementos dos vetores. Considerando os vetores v1 e v2 acima, o resultado do produto escalar é 5. Crie seu código que encontra esse resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4 - Faça uma multiplicação element-wise entre os vetores v1 e v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5 - Encontre o cosseno do vetor v1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 6 - Considere o vetor v e a matriz M abaixo. Multiplique o vetor pela matriz.\n",
    "\n",
    "A ordem dos objetos na multiplicação é relevante?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = array([1.,2.])\n",
    "M = array([[1.,2],[3.,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 7 - Usando a função solve() do pacote linalg do scipy, encontre a solução do sistema de equações lineares representado pelos 2 arrays abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as sl\n",
    "A = array([[1., 2.], \n",
    "           [3., 4.]])\n",
    "\n",
    "b = array([1., 4.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 8 - Explique porque a operação abaixo com os mesmos objetos A e b do exercício anterior apresenta resultado diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta: O resultado é diferente porque no exercício 7 estamos resolvendo um sistema de equações e os arrays são apenas representações destas equações. Aqui no exercício 8 estamos tratando os arrays apenas como listas de números e realizando multiplicação entre eles, o que é bem diferente de resolver equações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 9 - Desafio\n",
    "\n",
    "Considerando a matriz esparsa abaixo, pesquise pela função do pacote scipy que permite comprimir esta matriz.\n",
    "\n",
    "Nota: Matriz esparsa é uma matriz preenchida com mais valores 0 do que outros elementos. Comprimir a matriz significa exatamente remover os valores 0. Matrizes esparsas e compressão são amplamente utilizados em Machine Learning.\n",
    "\n",
    "Matrizes esparsas têm aplicações em problemas de engenharia e física (por exemplo, o método das malhas para resolução de circuitos elétricos ou sistemas de equações lineares). Também têm aplicação em computação: armazenamento de dados (e.g., planilhas eletrônicas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = array([[1,0,2,0],[0,0,0,0],[3.,0.,0.,0.],[1.,0.,0.,4.]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 10 - Super Desafio\n",
    "\n",
    "Abaixo você encontra uma classe Python que descreve uma rede neural artificial apenas com operações matemáticas. Não se deixe impressionar pelo código, é bem mais simples do que parece!!\n",
    "\n",
    "Seu trabalho é completar a função sigmoide (ao final da classe) com o código necessário para executar a operação matemática para esta que é uma função de ativação e define a saída de cada neurônio matemático.\n",
    "\n",
    "Estude o código, compreenda o que está sendo feito e complete a função sigmoide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Classe Network\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"A lista `sizes` contém o número de neurônios nas\n",
    "         respectivas camadas da rede. Por exemplo, se a lista\n",
    "         for [2, 3, 1] então será uma rede de três camadas, com o\n",
    "         primeira camada contendo 2 neurônios, a segunda camada 3 neurônios,\n",
    "         e a terceira camada 1 neurônio. Os bias e pesos para a\n",
    "         rede são inicializados aleatoriamente, usando uma distribuição Gaussiana com média 0 e variância 1. \n",
    "         Note que a primeira camada é assumida como uma camada de entrada, e por convenção nós\n",
    "         não definimos nenhum bias para esses neurônios, pois os bias são usados\n",
    "         na computação das saídas das camadas posteriores.\"\"\"\n",
    "\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Retorna a saída da rede se `a` for input.\"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n",
    "        \"\"\"Treinar a rede neural usando mini-batch stochastic\n",
    "        gradient descent. O `training_data` é uma lista de tuplas\n",
    "         `(x, y)` representando as entradas de treinamento e as\n",
    "         saídas. Os outros parâmetros não opcionais são\n",
    "         auto-explicativos. Se `test_data` for fornecido, então a\n",
    "         rede será avaliada em relação aos dados do teste após cada\n",
    "         época e progresso parcial impresso. Isso é útil para\n",
    "         acompanhar o progresso, mas retarda as coisas substancialmente.\"\"\"\n",
    "\n",
    "        training_data = list(training_data)\n",
    "        n = len(training_data)\n",
    "\n",
    "        if test_data:\n",
    "            test_data = list(test_data)\n",
    "            n_test = len(test_data)\n",
    "\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
    "            \n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            \n",
    "            if test_data:\n",
    "                print(\"Epoch {} : {} / {}\".format(j,self.evaluate(test_data),n_test));\n",
    "            else:\n",
    "                print(\"Epoch {} finalizada\".format(j))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \"\"\"Atualiza os pesos e bias da rede aplicando\n",
    "         a descida do gradiente usando backpropagation para um único mini lote.\n",
    "         O `mini_batch` é uma lista de tuplas `(x, y)`, e `eta` é a taxa de aprendizado.\"\"\"\n",
    "\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        \n",
    "        self.weights = [w-(eta/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Retorna uma tupla `(nabla_b, nabla_w)` representando o\n",
    "         gradiente para a função de custo C_x. `nabla_b` e\n",
    "         `nabla_w` são listas de camadas de matrizes numpy, semelhantes\n",
    "         a `self.biases` e `self.weights`.\"\"\"\n",
    "\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # Feedforward\n",
    "        activation = x\n",
    "\n",
    "        # Lista para armazenar todas as ativações, camada por camada\n",
    "        activations = [x] \n",
    "\n",
    "        # Lista para armazenar todos os vetores z, camada por camada\n",
    "        zs = [] \n",
    "\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        \n",
    "        # Backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        \n",
    "        # Aqui, l = 1 significa a última camada de neurônios, l = 2 é a segunda e assim por diante. \n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Retorna o número de entradas de teste para as quais a rede neural \n",
    "         produz o resultado correto. Note que a saída da rede neural\n",
    "         é considerada o índice de qualquer que seja\n",
    "         neurônio na camada final que tenha a maior ativação.\"\"\"\n",
    "\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Retorna o vetor das derivadas parciais.\"\"\"\n",
    "        return (output_activations-y)\n",
    "\n",
    "# Função de Ativação Sigmóide\n",
    "def sigmoid(z):\n",
    "    # RESOLVER AQUI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
